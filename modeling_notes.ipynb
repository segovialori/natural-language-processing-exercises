{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Modeling\n",
    "\n",
    "The \"big idea\" of modeling is to determine what a document is all about; which words are important or not. The main task is to determine the weight of each word, relative to the document.\n",
    "\n",
    "\n",
    "## What\n",
    "- Introducing our _Dramatis Personae_, the characters in our play:\n",
    "    - `Term frequency` is a direct way to measure what a document is about, but it over-emphasizes common terms. Consider term frequency the baseline, kinda like how median, median, or mode can be baselines. It's at least somewhere to start, even if it's a blunt tool w/ some issues.\n",
    "    - `TF` = # times a word occurs divided by the total amount of words. \n",
    "    - `Bag of words` is a representation of a document as a vector, where the values indicate word frequency.\n",
    "        ```\n",
    "        string = \"Mary had a little lamb, little lamb, little lamb.\"\n",
    "        string = string.replace(\",\", \"\")\n",
    "        words = string.split()\n",
    "        bag_of_words = pd.Series(words).value_counts()\n",
    "        ```\n",
    "    - Word clouds are a visual bag of words with larger font sizes representing higher term frequency\n",
    "    - Inverse Document Frequency, `IDF`, tells us how much information a word provides. \n",
    "        - A higher IDF means that a word provides more information. That is, it is more relevant within a single document.\n",
    "        - As the number of documents that a word appears in increases, the IDF value decreases.\n",
    "        - Example: if \"Codeup\" appears frequently in every document in a list of documents, then the word doesn't add much new information on any given individual document.\n",
    "        - Example: if \"scholarship\" shows up a whole bunch one one or two documents, but not frequently across the corups of documents, then we can conclude that that word conveys more meaning.\n",
    "        \n",
    "    - `TF-IDF` is the product of `tf * idf` and is \n",
    "\n",
    "\n",
    "## So What?\n",
    "- Determining what a document is about is both valuable and challening.\n",
    "- Term frequency is super sensitive to noise\n",
    "- TF-IDF is super common and has been used in the majority of text based recommendation systems. See [tf-idf in Wikipedia](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)\n",
    "\n",
    "## Now What?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf-idf is the product of tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>line</th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Encounter at Farpoint</td>\n",
       "      <td>Difficult? Simply solve the mystery of Farpoi...</td>\n",
       "      <td>DATA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Encounter at Farpoint</td>\n",
       "      <td>As simple as that.</td>\n",
       "      <td>PICARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Encounter at Farpoint</td>\n",
       "      <td>Farpoint Station. Even the name sounds myster...</td>\n",
       "      <td>TROI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Encounter at Farpoint</td>\n",
       "      <td>It's hardly simple, Data, to negotiate a frie...</td>\n",
       "      <td>PICARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encounter at Farpoint</td>\n",
       "      <td>Inquiry. The word snoop?</td>\n",
       "      <td>DATA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51983</th>\n",
       "      <td>All Good Things</td>\n",
       "      <td>Of course. Have a seat.</td>\n",
       "      <td>RIKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51984</th>\n",
       "      <td>All Good Things</td>\n",
       "      <td>Would you care to deal, sir?</td>\n",
       "      <td>DATA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51985</th>\n",
       "      <td>All Good Things</td>\n",
       "      <td>Oh, er, thank you, Mister Data. Actually, I u...</td>\n",
       "      <td>PICARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51986</th>\n",
       "      <td>All Good Things</td>\n",
       "      <td>You were always welcome.</td>\n",
       "      <td>TROI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51987</th>\n",
       "      <td>All Good Things</td>\n",
       "      <td>So. Five card stud, nothing wild, and the sky...</td>\n",
       "      <td>PICARD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38931 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                episode_name  \\\n",
       "0      Encounter at Farpoint   \n",
       "1      Encounter at Farpoint   \n",
       "2      Encounter at Farpoint   \n",
       "3      Encounter at Farpoint   \n",
       "4      Encounter at Farpoint   \n",
       "...                      ...   \n",
       "51983        All Good Things   \n",
       "51984        All Good Things   \n",
       "51985        All Good Things   \n",
       "51986        All Good Things   \n",
       "51987        All Good Things   \n",
       "\n",
       "                                                    line character  \n",
       "0       Difficult? Simply solve the mystery of Farpoi...      DATA  \n",
       "1                                     As simple as that.    PICARD  \n",
       "2       Farpoint Station. Even the name sounds myster...      TROI  \n",
       "3       It's hardly simple, Data, to negotiate a frie...    PICARD  \n",
       "4                               Inquiry. The word snoop?      DATA  \n",
       "...                                                  ...       ...  \n",
       "51983                            Of course. Have a seat.     RIKER  \n",
       "51984                       Would you care to deal, sir?      DATA  \n",
       "51985   Oh, er, thank you, Mister Data. Actually, I u...    PICARD  \n",
       "51986                           You were always welcome.      TROI  \n",
       "51987   So. Five card stud, nothing wild, and the sky...    PICARD  \n",
       "\n",
       "[38931 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grab the first 15 characters with most line\n",
    "df = pd.read_csv(\"tng.txt\")\n",
    "\n",
    "top_15_characters = df.character.value_counts().index[0:15]\n",
    "\n",
    "top_15 = df[df.character.isin(top_15_characters)]\n",
    "top_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADDITIONAL_STOPWORDS = ['r', 'u', '2', 'ltgt'] #ltgt is html artifact\n",
    "\n",
    "def clean(text):\n",
    "    'A simple function to cleanup text data'\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    stopwords = nltk.corpus.stopwords.words('english') + ADDITIONAL_STOPWORDS\n",
    "    text = (unicodedata.normalize('NFKD', text)\n",
    "             .encode('ascii', 'ignore')\n",
    "             .decode('utf-8', 'ignore')\n",
    "             .lower())\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split()\n",
    "    return \" \".join([wnl.lemmatize(word) for word in words if word not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use this split function later to create in-sample and out-of-sample datasets for modeling\n",
    "def split(df, stratify_by=None):\n",
    "    \"\"\"\n",
    "    3 way split for train, validate, and test datasets\n",
    "    To stratify, send in a column name\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    train, test = train_test_split(df, test_size=.2, random_state=123, stratify=df[stratify_by])\n",
    "    \n",
    "    train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train[stratify_by])\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- end goal: predicting what character said what line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>line</th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43382</th>\n",
       "      <td>Second Chances</td>\n",
       "      <td>The transporters are considerably more effici...</td>\n",
       "      <td>DATA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25169</th>\n",
       "      <td>The Loss</td>\n",
       "      <td>I look around me and all I see are surfaces w...</td>\n",
       "      <td>TROI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5207</th>\n",
       "      <td>Coming Of Age</td>\n",
       "      <td>All right. \\nCaptain's log, stardate 41416.2....</td>\n",
       "      <td>WESLEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40494</th>\n",
       "      <td>Ship in a Bottle</td>\n",
       "      <td>My ship is in danger. It is imperative that I...</td>\n",
       "      <td>PICARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7290</th>\n",
       "      <td>Conspiracy</td>\n",
       "      <td>Three, sir. All gathered inside what appears ...</td>\n",
       "      <td>DATA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           episode_name                                               line  \\\n",
       "43382    Second Chances   The transporters are considerably more effici...   \n",
       "25169          The Loss   I look around me and all I see are surfaces w...   \n",
       "5207      Coming Of Age   All right. \\nCaptain's log, stardate 41416.2....   \n",
       "40494  Ship in a Bottle   My ship is in danger. It is imperative that I...   \n",
       "7290         Conspiracy   Three, sir. All gathered inside what appears ...   \n",
       "\n",
       "      character  \n",
       "43382      DATA  \n",
       "25169      TROI  \n",
       "5207     WESLEY  \n",
       "40494    PICARD  \n",
       "7290       DATA  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, validate, test = split(top_15, 'character')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our X variables\n",
    "X_train = train.line\n",
    "X_validate = validate.line\n",
    "X_test = test.line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our y variables\n",
    "y_train = train.character\n",
    "y_validate = validate.character\n",
    "y_test = test.character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All text\n",
    "#\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#like one hot encodoing\n",
    "#produces a matric for each line\n",
    "#not a scaler, but basically like an encoder\n",
    "\n",
    "# Create the tfidf vectorizer object\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# Fit on the training data\n",
    "tfidf.fit(X_train)\n",
    "\n",
    "#use the object\n",
    "X_train_vectorized = tfidf.transform(X_train)\n",
    "X_validate_vectorized = tfidf.transform(X_validate)\n",
    "X_test_vectorized = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sparse vectors/matrices have tons of zeros\n",
    "#sparce matrix, an array with lots of 0\n",
    "#to dense to see what it looks like\n",
    "#every single word has a column, thats why there are so many zeros\n",
    "X-train_vectorized.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#something new but actually something old\n",
    "#now that we have vectorized dataset, we can use our classificaiton tools\n",
    "#remember we are trying to predict a discrete outcome\n",
    "#had to turn our words into numbers\n",
    "#want log regression bc we want a percentage\n",
    "lm = LogisticRegression()\n",
    "#fit the classification model on our vetorized train data\n",
    ".fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the trained model to predict y give those vectorized inputs of x\n",
    "train['predicted'] = lm.predict(X_train_vectorized)\n",
    "validate[\"predicted\"] = lm.predict(X_validate_vectorized)\n",
    "test['predicted'] = lm.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Accuracy\n",
    "(train.actual == train.predicted).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out of sample accuracy\n",
    "(validate.actual == validate.predicted).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that we have a trained model\n",
    "#lets use our mode to predict the character of any give line\n",
    "\n",
    "lines = pd.Series([\n",
    "    \"we have a responsibility\", \n",
    "    \"set phasers to stun\", \n",
    "    \"the warp drive is about to go critical\", \n",
    "    \"What does it mean to be human? I cannot calculate feelings\", \n",
    "    \"Romulan bird of prey decloaking off the port bow\"\n",
    "])\n",
    "\n",
    "#clean our inputs and lemmatize\n",
    "lines = lines.apply(clean)\n",
    "X = tfidf.transform(lines)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wesley = train[train.actual == \"WESLEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy\n",
    "(wesley.actual == wesley.predicted).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train[train.actual == \"DATA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data.actual == data.predicted).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull in classification report\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
