{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end result of this exercise should be a file named prepare.py that defines the requested functions.\n",
    "\n",
    "In this exercise we will be defining some functions to prepare textual data. These functions should apply equally well to both the codeup blog articles and the news articles that were previously acquired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import acquire as a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorisegovia/codeup-data-science/natural-language-processing-exercises/acquire.py:92: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 92 of the file /Users/lorisegovia/codeup-data-science/natural-language-processing-exercises/acquire.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(response.text)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Air India pilots demand vaccination on priorit...</td>\n",
       "      <td>Indian Commercial Pilots Association (ICPA) on...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India underestimated the coronavirus: Raghuram...</td>\n",
       "      <td>Speaking about India's second COVID-19 wave, f...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Korea's richest woman gets fortune worth...</td>\n",
       "      <td>South Korea’s richest woman Hong Ra-hee added ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>World's biggest jeweller says it will no longe...</td>\n",
       "      <td>Pandora, the world's biggest jeweller, has sai...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India announced triumph over COVID-19 early: U...</td>\n",
       "      <td>Confederation of Indian Industry (CII) Preside...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Air India pilots demand vaccination on priorit...   \n",
       "1  India underestimated the coronavirus: Raghuram...   \n",
       "2  South Korea's richest woman gets fortune worth...   \n",
       "3  World's biggest jeweller says it will no longe...   \n",
       "4  India announced triumph over COVID-19 early: U...   \n",
       "\n",
       "                                             content  category  \n",
       "0  Indian Commercial Pilots Association (ICPA) on...  business  \n",
       "1  Speaking about India's second COVID-19 wave, f...  business  \n",
       "2  South Korea’s richest woman Hong Ra-hee added ...  business  \n",
       "3  Pandora, the world's biggest jeweller, has sai...  business  \n",
       "4  Confederation of Indian Industry (CII) Preside...  business  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = a.get_all_news_articles(a.categories)\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clean\n",
    "def basic_clean(text):\n",
    "    \"\"\"\n",
    "    This function takes in one argument (text) and will apply\n",
    "    some basic text cleaning to it:\n",
    "    1. lowercase everything\n",
    "    2. normalize unicode characters\n",
    "    3. replace anything that is not a letter, number, whitespace,\n",
    "    or a single quote\n",
    "    \"\"\"\n",
    "    lowercase = text.lower()\n",
    "    normalize = unicodedata.normalize('NFKD', lowercase)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore')\n",
    "    remove_special = re.sub(r\"[^a-z0-9'\\s]\", '', normalize)\n",
    "    clean_text = remove_special\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"speaking about india's second covid19 wave former rbi governor raghuram rajan said i think what went wrong was simply thatwe underestimated the virus and its ability to adapt after the first wave there was a sense that we had endured the worstand we had come through and it was time to open up and that complacency hurt us he added\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure function works\n",
    "text = news_df.content[1]\n",
    "clean = basic_clean(text)\n",
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"South Korea’s richest woman Hong Ra-hee added another $7 billion (nearly ₹51,700 crore) worth of assets to her wealth. She received the amount in stocks after the transfer of her late husband and Samsung Group’s ex-Chairman Lee Kun-hee's assets. The 75-year-old inherited 83 million shares in Samsung Electronics, making her the largest individual shareholder in Samsung with a 2.3% stake.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grab some text to practice with\n",
    "text = news_df.content[2]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"south korea’s richest woman hong ra-hee added another $7 billion (nearly ₹51,700 crore) worth of assets to her wealth. she received the amount in stocks after the transfer of her late husband and samsung group’s ex-chairman lee kun-hee's assets. the 75-year-old inherited 83 million shares in samsung electronics, making her the largest individual shareholder in samsung with a 2.3% stake.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lowercase the text\n",
    "lowercase = text.lower()\n",
    "lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize: Removing accented characters or non-ASCII characters\n",
    "normalize = unicodedata.normalize('NFKD', lowercase)\\\n",
    ".encode('ascii', 'ignore')\\\n",
    ".decode('utf-8', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"south koreas richest woman hong ra-hee added another $7 billion (nearly 51,700 crore) worth of assets to her wealth. she received the amount in stocks after the transfer of her late husband and samsung groups ex-chairman lee kun-hee's assets. the 75-year-old inherited 83 million shares in samsung electronics, making her the largest individual shareholder in samsung with a 2.3% stake.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"south koreas richest woman hong rahee added another 7 billion nearly 51700 crore worth of assets to her wealth she received the amount in stocks after the transfer of her late husband and samsung groups exchairman lee kunhee's assets the 75yearold inherited 83 million shares in samsung electronics making her the largest individual shareholder in samsung with a 23 stake\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove special characters\n",
    "remove_special = re.sub(r\"[^a-z0-9'\\s]\", '', normalize)\n",
    "remove_special"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to tokenize\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    This function will take in one argument(text) and will\n",
    "    tokenize all words in the text.\n",
    "    \"\"\"\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    tokens = tokenizer.tokenize(basic_clean(text))\n",
    "    \n",
    "    return tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tokenizer\n",
    "tokenizer = nltk.tokenize.ToktokTokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['speaking',\n",
       " 'about',\n",
       " 'india',\n",
       " \"'\",\n",
       " 's',\n",
       " 'second',\n",
       " 'covid19',\n",
       " 'wave',\n",
       " 'former',\n",
       " 'rbi',\n",
       " 'governor',\n",
       " 'raghuram',\n",
       " 'rajan',\n",
       " 'said',\n",
       " 'i',\n",
       " 'think',\n",
       " 'what',\n",
       " 'went',\n",
       " 'wrong',\n",
       " 'was',\n",
       " 'simply',\n",
       " 'thatwe',\n",
       " 'underestimated',\n",
       " 'the',\n",
       " 'virus',\n",
       " 'and',\n",
       " 'its',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'adapt',\n",
       " 'after',\n",
       " 'the',\n",
       " 'first',\n",
       " 'wave',\n",
       " 'there',\n",
       " 'was',\n",
       " 'a',\n",
       " 'sense',\n",
       " 'that',\n",
       " 'we',\n",
       " 'had',\n",
       " 'endured',\n",
       " 'the',\n",
       " 'worstand',\n",
       " 'we',\n",
       " 'had',\n",
       " 'come',\n",
       " 'through',\n",
       " 'and',\n",
       " 'it',\n",
       " 'was',\n",
       " 'time',\n",
       " 'to',\n",
       " 'open',\n",
       " 'up',\n",
       " 'and',\n",
       " 'that',\n",
       " 'complacency',\n",
       " 'hurt',\n",
       " 'us',\n",
       " 'he',\n",
       " 'added']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the tokenizer\n",
    "tokenizer.tokenize(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokens = tokenizer.tokenize(basic_clean(text))\n",
    "#tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['indian',\n",
       " 'commercial',\n",
       " 'pilots',\n",
       " 'association',\n",
       " 'icpa',\n",
       " 'on',\n",
       " 'tuesday',\n",
       " 'said',\n",
       " 'if',\n",
       " 'air',\n",
       " 'india',\n",
       " 'fails',\n",
       " 'to',\n",
       " 'set',\n",
       " 'up',\n",
       " 'vaccination',\n",
       " 'camps',\n",
       " 'on',\n",
       " 'a',\n",
       " 'panindia',\n",
       " 'basis',\n",
       " 'forflying',\n",
       " 'crew',\n",
       " 'above',\n",
       " 'the',\n",
       " 'age',\n",
       " 'of',\n",
       " '18',\n",
       " 'years',\n",
       " 'on',\n",
       " 'priority',\n",
       " 'we',\n",
       " \"'\",\n",
       " 'll',\n",
       " 'stop',\n",
       " 'work',\n",
       " 'in',\n",
       " 'a',\n",
       " 'letter',\n",
       " 'to',\n",
       " 'the',\n",
       " 'airline',\n",
       " \"'\",\n",
       " 's',\n",
       " 'management',\n",
       " 'icpa',\n",
       " 'added',\n",
       " 'with',\n",
       " 'no',\n",
       " 'healthcare',\n",
       " 'supportno',\n",
       " 'insurancewe',\n",
       " \"'\",\n",
       " 're',\n",
       " 'in',\n",
       " 'no',\n",
       " 'position',\n",
       " 'to',\n",
       " 'continue',\n",
       " 'risking',\n",
       " 'lives',\n",
       " 'of',\n",
       " 'our',\n",
       " 'pilots',\n",
       " 'without',\n",
       " 'vaccination']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure function works\n",
    "text = news_df.content[0]\n",
    "tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to stem\n",
    "def stem(text):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to lemmatize\n",
    "def lemmatize(text):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "- This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove stop words\n",
    "def remove_stopwords(text):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. For each dataframe, produce the following columns:\n",
    "- title to hold the title\n",
    "- original to hold the original article/post content\n",
    "- clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "- stemmed to hold the stemmed version of the cleaned data.\n",
    "- lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "- If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "- If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
